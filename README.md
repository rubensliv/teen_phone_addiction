# teen_phone_addiction
'''
DescriÃ§Ã£o Geral da Base de Dados: teen_phone_addiction_dataset.csv
Essa base parece estar relacionada ao nÃ­vel de vÃ­cio em celular entre adolescentes. 
Foi construÃ­da a partir de questionÃ¡rios, entrevistas ou registros comportamentais de jovens, 
com o objetivo de prever o grau de dependÃªncia do celular com base em diversos fatores.

ğŸ” Estrutura esperada da base de dados

âœ… Colunas que foram removidas:
ID: identificador Ãºnico de cada adolescente â€” sem utilidade para prediÃ§Ã£o.

Name: nome da pessoa â€” tambÃ©m irrelevante para o modelo.

ğŸ¯ VariÃ¡vel alvo (target):

Addiction_Level: nÃ­vel de dependÃªncia do celular (provavelmente numÃ©rico e contÃ­nuo).
Ex: pode ir de 0 a 10, onde 0 = sem dependÃªncia, 10 = alto vÃ­cio.

ğŸ“¥ VariÃ¡veis preditoras (features):

O restante das colunas foi usado para prever o Addiction_Level. Devem incluir:

Tipo de variÃ¡vel	Exemplos possÃ­veis

CategÃ³ricas	        GÃªnero, Tipo de escola, OcupaÃ§Ã£o dos pais
NumÃ©ricas	        Horas no celular por dia, notas escolares, idade
Comportamentais	    FrequÃªncia de uso de redes sociais, jogos, etc.

Essas variÃ¡veis foram:

Codificadas com LabelEncoder (as categÃ³ricas).

Normalizadas com StandardScaler (as numÃ©ricas).

Filtradas por outliers usando a tÃ©cnica do IQR.


Este programa estÃ¡ estruturado para resolver uma tarefa de regressÃ£o supervisionada com o
algoritmo XGBoost, que Ã© altamente eficaz e usado em competiÃ§Ãµes de Machine Learning.

âœ… Pontos fortes:

Realiza todo o pipeline: leitura, limpeza, codificaÃ§Ã£o, divisÃ£o dos dados, treinamento, avaliaÃ§Ã£o e
interpretaÃ§Ã£o.

Usa o LabelEncoder  para lidar com variÃ¡veis categÃ³ricas automaticamente.

Avalia o modelo com mÃ©tricas apropriadas (RMSE e RÂ²).

Apresenta visualmente a importÃ¢ncia das features â€” Ãºtil para anÃ¡lise interpretativa.


âš ï¸ SugestÃµes de melhorias opcionais:

NormalizaÃ§Ã£o de variÃ¡veis: pode melhorar a performance, principalmente se adicionar outros algoritmos
alÃ©m do XGBoost.

ValidaÃ§Ã£o cruzada (cross-validation): para obter resultados mais robustos e evitar overfitting.

GridSearch ou RandomizedSearch: para ajustar hiperparÃ¢metros do XGBoost.

Salvar o modelo treinado com joblib ou pickle se for usar em produÃ§Ã£o.

'''
